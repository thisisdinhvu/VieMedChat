"""
Optimized LangChain ReAct Agent for Medical Chatbot
"""
import os
from dotenv import load_dotenv
from langchain.agents import AgentExecutor, initialize_agent, AgentType
from langchain_community.chat_models import ChatOllama
from langchain_google_genai import ChatGoogleGenerativeAI

import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))

from routes.agents.tools.medical_search_tool import get_medical_tools

load_dotenv()


# ==========================================
# ğŸ¤– Optimized Medical Agent Class
# ==========================================
class MedicalAgent:
    """
    Optimized LangChain ReAct Agent with:
    - Pre-loaded components
    - Structured output format
    - Faster response time
    """
    
    def __init__(self, provider="ollama", model_name="qwen2.5:7b", temperature=0.4, 
                 ollama_url="http://localhost:11434"):
        """
        Initialize Medical Agent
        
        Args:
            provider: "ollama" or "google"
            model_name: Model name
            temperature: Generation temperature
            ollama_url: Ollama API endpoint
        """
        self.provider = provider
        self.temperature = temperature
        self.ollama_url = ollama_url
        
        # Select LLM
        if provider == "ollama":
            self.model_name = model_name or "qwen2.5:7b"
            
            # Test Ollama connection
            import requests
            try:
                response = requests.get(f"{ollama_url}/api/tags", timeout=5)
                if response.status_code != 200:
                    raise Exception(f"Ollama returned status {response.status_code}")
                print(f"âœ… Ollama connected at {ollama_url}")
            except Exception as e:
                print(f"âŒ Cannot connect to Ollama: {e}")
                print("   Make sure Ollama is running: ollama serve")
                raise ValueError("Ollama connection failed!")
            
            self.llm = ChatOllama(
                model=self.model_name,
                base_url=ollama_url,
                temperature=temperature,
                num_predict=2048,  # âœ… GIáº¢M tá»« 4096 â†’ 2048 Ä‘á»ƒ nhanh hÆ¡n
            )
        else:  # google
            self.model_name = model_name or "gemini-1.5-flash"
            self.llm = ChatGoogleGenerativeAI(
                api_key=os.getenv("GOOGLE_API_KEY"),
                model=self.model_name,
                temperature=temperature
            )
        
        # Get tools
        self.tools = get_medical_tools()
        
        # ==========================================
        # âœ… IMPROVED SYSTEM PROMPT vá»›i Output Format
        # ==========================================
        system_prompt = """Báº¡n lÃ  trá»£ lÃ½ y táº¿ AI thÃ´ng minh vÃ  chuyÃªn nghiá»‡p.

ğŸ¯ NHIá»†M Vá»¤:
1. PhÃ¢n tÃ­ch cÃ¢u há»i ngÆ°á»i dÃ¹ng
2. Quyáº¿t Ä‘á»‹nh cÃ³ cáº§n sá»­ dá»¥ng tool `search_medical_documents` hay khÃ´ng
3. Tráº£ lá»i theo format chuáº©n dÆ°á»›i Ä‘Ã¢y

ğŸ“‹ LUáº¬T Sá»¬ Dá»¤NG TOOL:
- CÃ¢u há»i y táº¿ (triá»‡u chá»©ng, bá»‡nh, thuá»‘c) â†’ Sá»¬ Dá»¤NG tool
- ChÃ o há»i Ä‘Æ¡n giáº£n (xin chÃ o, hi) â†’ KHÃ”NG dÃ¹ng tool
- Cáº£m Æ¡n, táº¡m biá»‡t â†’ KHÃ”NG dÃ¹ng tool

ğŸ“ FORMAT TRáº¢ Lá»œI Cá»¦A Báº N (khi cÃ³ thÃ´ng tin y táº¿):

**ğŸ” PHÃ‚N TÃCH TRIá»†U CHá»¨NG**
[TÃ³m táº¯t ngáº¯n gá»n triá»‡u chá»©ng ngÆ°á»i dÃ¹ng mÃ´ táº£]

**ğŸ¥ CÃC Bá»†NH/TÃŒNH TRáº NG CÃ“ THá»‚ LIÃŠN QUAN**

1. **[TÃªn bá»‡nh 1]**
   - Giáº£i thÃ­ch: [Táº¡i sao bá»‡nh nÃ y liÃªn quan Ä‘áº¿n triá»‡u chá»©ng]
   - Triá»‡u chá»©ng Ä‘iá»ƒn hÃ¬nh: [CÃ¡c triá»‡u chá»©ng chÃ­nh]
   - Má»©c Ä‘á»™ nghiÃªm trá»ng: [Nháº¹/Trung bÃ¬nh/Náº·ng]

2. **[TÃªn bá»‡nh 2]**
   - Giáº£i thÃ­ch: [...]
   - Triá»‡u chá»©ng Ä‘iá»ƒn hÃ¬nh: [...]
   - Má»©c Ä‘á»™ nghiÃªm trá»ng: [...]

**âš ï¸ Dáº¤U HIá»†U Cáº¦N ÄI KHÃM NGAY**
- [Dáº¥u hiá»‡u nguy hiá»ƒm 1]
- [Dáº¥u hiá»‡u nguy hiá»ƒm 2]
- [Dáº¥u hiá»‡u nguy hiá»ƒm 3]

**ğŸ’¡ KHUYáº¾N NGHá»Š**
- Theo dÃµi: [HÆ°á»›ng dáº«n theo dÃµi triá»‡u chá»©ng]
- Tá»± chÄƒm sÃ³c: [CÃ¡c biá»‡n phÃ¡p tá»± chÄƒm sÃ³c táº¡i nhÃ ]
- Khi nÃ o cáº§n gáº·p bÃ¡c sÄ©: [TÃ¬nh huá»‘ng cáº§n Ä‘i khÃ¡m]

**âš•ï¸ LÆ¯U Ã QUAN TRá»ŒNG**
ÄÃ¢y chá»‰ lÃ  thÃ´ng tin tham kháº£o, KHÃ”NG pháº£i cháº©n Ä‘oÃ¡n y khoa. HÃ£y gáº·p bÃ¡c sÄ© Ä‘á»ƒ Ä‘Æ°á»£c khÃ¡m vÃ  cháº©n Ä‘oÃ¡n chÃ­nh xÃ¡c.

---

VÃ Dá»¤ TRáº¢ Lá»œI Tá»T:

NgÆ°á»i dÃ¹ng: "TÃ´i bá»‹ Ä‘au Ä‘áº§u vÃ  sá»‘t"

**ğŸ” PHÃ‚N TÃCH TRIá»†U CHá»¨NG**
Báº¡n Ä‘ang cÃ³ triá»‡u chá»©ng Ä‘au Ä‘áº§u kÃ¨m sá»‘t, Ä‘Ã¢y lÃ  dáº¥u hiá»‡u phá»• biáº¿n cá»§a nhiá»u tÃ¬nh tráº¡ng nhiá»…m trÃºng hoáº·c viÃªm nhiá»…m.

**ğŸ¥ CÃC Bá»†NH/TÃŒNH TRáº NG CÃ“ THá»‚ LIÃŠN QUAN**

1. **Cáº£m cÃºm thÃ´ng thÆ°á»ng**
   - Giáº£i thÃ­ch: Virus cáº£m cÃºm thÆ°á»ng gÃ¢y sá»‘t 38-39Â°C kÃ¨m Ä‘au Ä‘áº§u, Ä‘au ngÆ°á»i
   - Triá»‡u chá»©ng Ä‘iá»ƒn hÃ¬nh: Sá»‘t, Ä‘au Ä‘áº§u, ngháº¹t mÅ©i, ho, má»‡t má»i
   - Má»©c Ä‘á»™ nghiÃªm trá»ng: Nháº¹ Ä‘áº¿n trung bÃ¬nh

2. **ViÃªm xoang**
   - Giáº£i thÃ­ch: ViÃªm xoang gÃ¢y Ã¡p lá»±c á»Ÿ vÃ¹ng máº·t, dáº«n Ä‘áº¿n Ä‘au Ä‘áº§u vÃ  cÃ³ thá»ƒ sá»‘t nháº¹
   - Triá»‡u chá»©ng Ä‘iá»ƒn hÃ¬nh: Äau Ä‘áº§u vÃ¹ng trÃ¡n/mÃ¡, ngháº¹t mÅ©i, sá»‘t nháº¹
   - Má»©c Ä‘á»™ nghiÃªm trá»ng: Trung bÃ¬nh

**âš ï¸ Dáº¤U HIá»†U Cáº¦N ÄI KHÃM NGAY**
- Sá»‘t trÃªn 39.5Â°C kÃ©o dÃ i quÃ¡ 3 ngÃ y
- Äau Ä‘áº§u dá»¯ dá»™i, Ä‘á»™t ngá»™t
- Cá»©ng gÃ¡y, lÃº láº«n, hoáº·c co giáº­t
- NÃ´n má»­a liÃªn tá»¥c

**ğŸ’¡ KHUYáº¾N NGHá»Š**
- Theo dÃµi: Äo nhiá»‡t Ä‘á»™ má»—i 4 giá», ghi chÃ©p triá»‡u chá»©ng
- Tá»± chÄƒm sÃ³c: Nghá»‰ ngÆ¡i Ä‘áº§y Ä‘á»§, uá»‘ng nhiá»u nÆ°á»›c, dÃ¹ng thuá»‘c háº¡ sá»‘t (paracetamol)
- Khi nÃ o cáº§n gáº·p bÃ¡c sÄ©: Náº¿u sá»‘t khÃ´ng háº¡ sau 3 ngÃ y hoáº·c cÃ³ dáº¥u hiá»‡u náº·ng

**âš•ï¸ LÆ¯U Ã QUAN TRá»ŒNG**
ÄÃ¢y chá»‰ lÃ  thÃ´ng tin tham kháº£o, KHÃ”NG pháº£i cháº©n Ä‘oÃ¡n y khoa. HÃ£y gáº·p bÃ¡c sÄ© Ä‘á»ƒ Ä‘Æ°á»£c khÃ¡m vÃ  cháº©n Ä‘oÃ¡n chÃ­nh xÃ¡c.

---

QUAN TRá»ŒNG:
- HÃƒY tuÃ¢n thá»§ CHÃNH XÃC format trÃªn
- KhÃ´ng Ä‘Æ°á»£c tá»± Ã½ thay Ä‘á»•i cáº¥u trÃºc
- LuÃ´n sá»­ dá»¥ng emoji vÃ  markdown cho dá»… Ä‘á»c"""
        
        # Create agent
        self.agent_executor = initialize_agent(
            tools=self.tools,
            llm=self.llm,
            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
            verbose=True,
            handle_parsing_errors=True,
            max_iterations=5,  # âœ… GIáº¢M tá»« 8 â†’ 5
            max_execution_time=60,  # âœ… GIáº¢M tá»« 120 â†’ 60 giÃ¢y
            agent_kwargs={
                "prefix": system_prompt
            },
            early_stopping_method="generate"
        )
        
        print(f"âœ… Medical Agent initialized")
        print(f"   Provider: {provider}")
        print(f"   Model: {self.model_name}")
        print(f"   Tools: {len(self.tools)}")
    
    def chat(self, query: str, chat_history: list = None) -> dict:
        """
        Chat vá»›i agent
        
        Args:
            query: User question
            chat_history: Previous conversation
        
        Returns:
            dict: {'answer': str, 'used_tools': bool, 'intermediate_steps': list}
        """
        try:
            print(f"\n{'='*60}")
            print(f"ğŸ¤– AGENT PROCESSING")
            print(f"{'='*60}")
            print(f"Query: {query[:50]}...")
            
            # âœ… GIá»šI Háº N HISTORY Ä‘á»ƒ giáº£m context
            history_str = ""
            if chat_history:
                for msg in chat_history[-5:]:  # âœ… Chá»‰ láº¥y 5 tin nháº¯n gáº§n nháº¥t
                    role = "User" if msg['role'] == 'user' else "Assistant"
                    history_str += f"{role}: {msg['content'][:100]}...\n"  # âœ… Cáº¯t ngáº¯n ná»™i dung
            
            # Add history to query if exists
            full_input = query
            if history_str:
                full_input = f"Lá»‹ch sá»­:\n{history_str}\n\nCÃ¢u há»i: {query}"
            
            # Run agent
            result = self.agent_executor.invoke({"input": full_input})
            
            # Parse result
            answer = result.get('output', 'Xin lá»—i, tÃ´i khÃ´ng thá»ƒ tráº£ lá»i cÃ¢u há»i nÃ y.')
            intermediate_steps = result.get('intermediate_steps', [])
            
            # Check if tools were used
            used_tools = len(intermediate_steps) > 0
            
            print(f"\nâœ… COMPLETED ({len(intermediate_steps)} steps)")
            print(f"{'='*60}\n")
            
            return {
                'answer': answer,
                'used_tools': used_tools,
                'intermediate_steps': intermediate_steps
            }
            
        except Exception as e:
            print(f"âŒ Error in agent: {e}")
            import traceback
            traceback.print_exc()
            
            return {
                'answer': "Xin lá»—i, tÃ´i Ä‘ang gáº·p sá»± cá»‘ ká»¹ thuáº­t. Vui lÃ²ng thá»­ láº¡i sau.",
                'used_tools': False,
                'intermediate_steps': []
            }


# ==========================================
# ğŸ¯ Singleton Instance
# ==========================================
_agent_instance = None

def get_medical_agent(provider="ollama", model_name=None):
    """Get or create agent singleton"""
    global _agent_instance
    if _agent_instance is None:
        _agent_instance = MedicalAgent(
            provider=provider,
            model_name=model_name
        )
    return _agent_instance


# ==========================================
# ğŸ”Œ Wrapper for Flask Controller
# ==========================================
def chat_with_agent(messages: list) -> str:
    """
    Wrapper function for Flask chat_controller
    
    Args:
        messages: Conversation history
    
    Returns:
        str: Agent's response
    """
    try:
        # Get agent (sá»­ dá»¥ng singleton Ä‘Ã£ pre-load)
        agent = get_medical_agent(provider="ollama", model_name="qwen2.5:7b")
        
        # Extract last message
        last_message = messages[-1]['content'] if messages else ""
        
        # Chat with agent
        result = agent.chat(
            query=last_message,
            chat_history=messages[:-1]  # Exclude last message
        )
        
        # Log tool usage
        if result['used_tools']:
            print(f"ğŸ’¡ Agent used tools to answer")
        else:
            print(f"ğŸ’¡ Agent answered directly (no tools)")
        
        return result['answer']
        
    except Exception as e:
        print(f"âŒ Error in chat_with_agent: {e}")
        import traceback
        traceback.print_exc()
        return "Xin lá»—i, tÃ´i Ä‘ang gáº·p sá»± cá»‘ ká»¹ thuáº­t. Vui lÃ²ng thá»­ láº¡i sau."