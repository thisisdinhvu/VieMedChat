"""
General Chat Tool for LangChain Agent
Handles casual conversation using LLM
"""
from langchain.tools import Tool
from pydantic import BaseModel, Field
from typing import Optional
import os
import sys

# Add backend to path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../..")))


# ==========================================
# üìä Input Schema
# ==========================================
class GeneralChatInput(BaseModel):
    """Input schema for general chat"""
    query: str = Field(
        description="C√¢u h·ªèi ho·∫∑c n·ªôi dung tr√≤ chuy·ªán th√¥ng th∆∞·ªùng c·ªßa ng∆∞·ªùi d√πng. "
                    "V√≠ d·ª•: 'xin ch√†o', 'b·∫°n t√™n g√¨', 'h√¥m nay th·∫ø n√†o'"
    )


# ==========================================
# üí¨ General Chat Function
# ==========================================
def general_chat(query: str) -> str:
    """
    Handle general conversation using LLM.
    
    Use this tool when:
    - User asks casual questions (greetings, small talk)
    - Questions about the bot itself ("b·∫°n l√† ai?", "b·∫°n l√†m g√¨?")
    - General chitchat not related to medical or calculations
    - Expressions of thanks, goodbye, etc.
    
    Do NOT use for:
    - Medical questions (use search_medical_documents)
    - Math calculations (use calculator)
    
    Examples:
    - "xin ch√†o" ‚Üí Use this tool
    - "b·∫°n t√™n g√¨?" ‚Üí Use this tool
    - "c·∫£m ∆°n" ‚Üí Use this tool
    - "ƒëau ƒë·∫ßu" ‚Üí Do NOT use (medical)
    - "2 + 2" ‚Üí Do NOT use (math)
    
    Args:
        query: User's casual question
    
    Returns:
        str: Friendly conversational response
    """
    try:
        print(f"\nüí¨ GENERAL CHAT TOOL CALLED")
        print(f"   Query: {query}")
        
        # Import LLM (lazy loading)
        from backend.routes.rag.llms import LLM
        
        # Initialize LLM for chat
        llm = LLM(
            # model_name="ollama/qwen2.5:7b",  # Fast small model for chat
            model_name="gemini-1.5-flash",
            # ollama_url="http://localhost:11434",
            temperature=0.4,  # Higher temp for more creative chat
            language="vi"
        )
        
        # Build casual chat prompt
        chat_prompt = f"""B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¢n thi·ªán v√† nhi·ªát t√¨nh.

Ng∆∞·ªùi d√πng n√≥i: "{query}"

H√£y tr·∫£ l·ªùi m·ªôt c√°ch ng·∫Øn g·ªçn, t·ª± nhi√™n v√† th√¢n thi·ªán (1-2 c√¢u).

L∆∞u √Ω:
- N·∫øu ƒë∆∞·ª£c h·ªèi v·ªÅ b·∫£n th√¢n: "T√¥i l√† tr·ª£ l√Ω AI y t·∫ø, c√≥ th·ªÉ gi√∫p b·∫°n t∆∞ v·∫•n v·ªÅ s·ª©c kh·ªèe"
- N·∫øu ƒë∆∞·ª£c c·∫£m ∆°n: "R·∫•t vui ƒë∆∞·ª£c gi√∫p ƒë·ª° b·∫°n!"
- N·∫øu ƒë∆∞·ª£c ch√†o: "Xin ch√†o! T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?"
- N·∫øu t·∫°m bi·ªát: "Ch√∫c b·∫°n m·ªôt ng√†y t·ªët l√†nh!"

Tr·∫£ l·ªùi:"""
        
        # Generate response
        response = llm.generate(chat_prompt)
        
        print(f"   ‚úÖ Response generated")
        
        return response.strip()
        
    except Exception as e:
        print(f"   ‚ùå Error in general_chat: {e}")
        import traceback
        traceback.print_exc()
        
        # Fallback responses
        query_lower = query.lower()
        
        if any(greeting in query_lower for greeting in ['ch√†o', 'hello', 'hi', 'hey']):
            return "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω AI y t·∫ø. T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n h√¥m nay?"
        
        elif any(thanks in query_lower for thanks in ['c·∫£m ∆°n', 'thank', 'thanks']):
            return "R·∫•t vui ƒë∆∞·ª£c gi√∫p ƒë·ª° b·∫°n! N·∫øu c√≥ c√¢u h·ªèi g√¨ kh√°c, ƒë·ª´ng ng·∫°i h·ªèi nh√©!"
        
        elif any(bye in query_lower for bye in ['t·∫°m bi·ªát', 'bye', 'goodbye']):
            return "T·∫°m bi·ªát! Ch√∫c b·∫°n m·ªôt ng√†y t·ªët l√†nh! üëã"
        
        elif 't√™n' in query_lower or 'l√† ai' in query_lower:
            return "T√¥i l√† tr·ª£ l√Ω AI y t·∫ø, ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ gi√∫p b·∫°n t∆∞ v·∫•n v·ªÅ c√°c v·∫•n ƒë·ªÅ s·ª©c kh·ªèe."
        
        else:
            return "T√¥i l√† tr·ª£ l√Ω AI y t·∫ø. B·∫°n c√≥ c√¢u h·ªèi g√¨ v·ªÅ s·ª©c kh·ªèe kh√¥ng? T√¥i s·∫µn s√†ng h·ªó tr·ª£!"


# ==========================================
# üõ†Ô∏è LangChain Tool Definition
# ==========================================
def get_general_chat_tool():
    """
    Get general chat tool for LangChain agent
    
    Returns:
        Tool: LangChain Tool object
    """
    return Tool(
        name="general_chat",
        func=general_chat,
        description="""
            C√¥ng c·ª• tr√≤ chuy·ªán th√¥ng th∆∞·ªùng, x·ª≠ l√Ω c√°c c√¢u h·ªèi chung chung.
            
            S·ª¨ D·ª§NG khi:
            - C√¢u ch√†o h·ªèi (xin ch√†o, hi, hello)
            - C√¢u h·ªèi v·ªÅ bot (b·∫°n l√† ai, t√™n g√¨, l√†m g√¨)
            - C·∫£m ∆°n, t·∫°m bi·ªát
            - Tr√≤ chuy·ªán th√¥ng th∆∞·ªùng, kh√¥ng li√™n quan y t·∫ø ho·∫∑c t√≠nh to√°n
            
            KH√îNG S·ª¨ D·ª§NG khi:
            - C√¢u h·ªèi y t·∫ø (tri·ªáu ch·ª©ng, b·ªánh, thu·ªëc) ‚Üí d√πng search_medical_documents
            - Ph√©p t√≠nh to√°n h·ªçc ‚Üí d√πng calculator
            
            V√≠ d·ª• s·ª≠ d·ª•ng:
            - "xin ch√†o" ‚Üí general_chat("xin ch√†o")
            - "b·∫°n t√™n g√¨?" ‚Üí general_chat("b·∫°n t√™n g√¨?")
            - "c·∫£m ∆°n b·∫°n" ‚Üí general_chat("c·∫£m ∆°n b·∫°n")
            
            Input: C√¢u h·ªèi chung (string)
            Output: C√¢u tr·∫£ l·ªùi th√¢n thi·ªán
        """,
        args_schema=GeneralChatInput,
        return_direct=False
    )