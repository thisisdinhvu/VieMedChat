# """
# Startup hook to pre-initialize heavy components
# Runs once when Flask server starts
# """
# import os
# from dotenv import load_dotenv
# from utils.rag_service import get_rag_service

# load_dotenv()


# def initialize_rag_components():
#     """
#     Pre-load all heavy components on startup:
#     - Embedding model (1024-dim, ~500MB)
#     - Pinecone index connection
#     - BM25 corpus (24k documents)
#     - Reranker model
    
#     This runs ONCE when server starts, not per-request.
#     """
#     print("\n" + "="*60)
#     print("üöÄ PRE-INITIALIZING RAG COMPONENTS")
#     print("="*60)
    
#     try:
#         # Get RAG service singleton
#         rag = get_rag_service(use_reranker=True)
        
#         # Force initialization of all lazy-loaded components
#         print("\n1Ô∏è‚É£ Loading Embedding Model & Pinecone...")
#         _ = rag.vectorstore  # Triggers embedding model load
        
#         print("\n2Ô∏è‚É£ Loading BM25 Corpus...")
#         _ = rag.splits  # Triggers corpus load
        
#         print("\n3Ô∏è‚É£ Initializing Search Engine...")
#         _ = rag.search_engine  # Triggers search setup
        
#         print("\n4Ô∏è‚É£ Loading Reranker...")
#         _ = rag.reranker  # Triggers reranker load
        
#         print("\n5Ô∏è‚É£ Loading LLM Client...")
#         _ = rag.llm  # Triggers LLM client setup
        
#         print("\n" + "="*60)
#         print("‚úÖ ALL COMPONENTS PRE-LOADED SUCCESSFULLY!")
#         print("="*60)
#         print("üí° Future requests will use cached components")
#         print("="*60 + "\n")
        
#         return True
        
#     except Exception as e:
#         print(f"\n‚ùå ERROR during pre-initialization: {e}")
#         import traceback
#         traceback.print_exc()
#         print("\n‚ö†Ô∏è Server will start but components will lazy-load per request")
#         return False


# def warmup_test():
#     """
#     Optional: Run a test query to verify everything works
#     """
#     print("\nüß™ Running warmup test query...")
    
#     try:
#         rag = get_rag_service()
#         result = rag.generate_answer(
#             query="Xin ch√†o",
#             use_rag=False,  # Don't retrieve context for warmup
#             include_context_in_response=False
#         )
        
#         if result['answer']:
#             print("‚úÖ Warmup test passed!")
#             return True
#         else:
#             print("‚ö†Ô∏è Warmup test returned empty response")
#             return False
            
#     except Exception as e:
#         print(f"‚ùå Warmup test failed: {e}")
#         return False


# if __name__ == "__main__":
#     # For testing
#     initialize_rag_components()
#     warmup_test()

"""
Optimized Startup Hook - Pre-initialize ALL heavy components
Runs ONCE when Flask server starts
"""
import os
from dotenv import load_dotenv
from utils.rag_service import get_rag_service
from routes.agents.medical_agent import get_medical_agent

load_dotenv()


def initialize_rag_components():
    """
    Pre-load ALL heavy components on startup:
    - Embedding model (1024-dim, ~500MB) ‚úÖ
    - Pinecone index connection ‚úÖ
    - BM25 corpus (24k documents) ‚úÖ
    - Reranker model ‚úÖ
    - LLM client ‚úÖ
    - Agent instance ‚úÖ
    
    This runs ONCE when server starts, not per-request.
    """
    print("\n" + "="*60)
    print("üöÄ PRE-INITIALIZING RAG COMPONENTS")
    print("="*60)
    
    try:
        # ==========================================
        # 1. Pre-load RAG Service Components
        # ==========================================
        rag = get_rag_service(use_reranker=True)
        
        print("\n1Ô∏è‚É£ Loading Embedding Model & Pinecone...")
        _ = rag.vectorstore  # Triggers embedding model load
        
        print("\n2Ô∏è‚É£ Loading BM25 Corpus...")
        _ = rag.splits  # Triggers corpus load
        
        print("\n3Ô∏è‚É£ Initializing Search Engine...")
        _ = rag.search_engine  # Triggers search setup
        
        print("\n4Ô∏è‚É£ Loading Reranker...")
        _ = rag.reranker  # Triggers reranker load
        
        print("\n5Ô∏è‚É£ Loading LLM Client...")
        _ = rag.llm  # Triggers LLM client setup
        
        # ==========================================
        # 2. Pre-load Agent (CRITICAL for speed!)
        # ==========================================
        print("\n6Ô∏è‚É£ Pre-loading Medical Agent...")
        agent = get_medical_agent(provider="ollama", model_name="llama3.2:3b")
        
        # Warm up agent with a test query
        print("\n7Ô∏è‚É£ Warming up agent with test query...")
        test_result = agent.chat(
            query="xin ch√†o",
            chat_history=[]
        )
        if test_result['answer']:
            print("   ‚úÖ Agent warmup successful!")
        
        print("\n" + "="*60)
        print("‚úÖ ALL COMPONENTS PRE-LOADED SUCCESSFULLY!")
        print("="*60)
        print("üí° Future requests will use cached components")
        print("üí° Expected response time: 2-5 seconds (down from 15-20s)")
        print("="*60 + "\n")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå ERROR during pre-initialization: {e}")
        import traceback
        traceback.print_exc()
        print("\n‚ö†Ô∏è Server will start but components will lazy-load per request")
        return False
